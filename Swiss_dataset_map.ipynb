{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49217db",
   "metadata": {},
   "source": [
    "# Swiss rail network map\n",
    "\n",
    "Compare the SBB-specific graph with the nationwide `schienennetz_2056_de` graph. Each map cell below focuses on a single dataset so you can inspect them independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = Path('datasets/switzerland')\n",
    "SBB_STATION_PATH = BASE_DIR / 'sbb-dienststellen-gemass-opentransportdataswiss.csv'\n",
    "\n",
    "DATASET_CONFIGS = [\n",
    "    {\n",
    "        'key': 'sbb',\n",
    "        'label': 'SBB (opentransportdata)',\n",
    "        'path': BASE_DIR / 'sbb_rail_network.gpickle',\n",
    "        'fallback_paths': [BASE_DIR / 'swiss_rail_network.gpickle'],\n",
    "        'node_colors': ('#1f77b4', '#ff7f0e'),\n",
    "        'edge_color': '#6c757d',\n",
    "        'show': True,\n",
    "    },\n",
    "    {\n",
    "        'key': 'swisstopo',\n",
    "        'label': 'swisstopo (schienennetz_2056_de)',\n",
    "        'path': BASE_DIR / 'swiss_rail_network_swisstopo.gpickle',\n",
    "        'fallback_paths': [],\n",
    "        'node_colors': ('#2ca02c', '#d62728'),\n",
    "        'edge_color': '#4b3f72',\n",
    "        'show': True,\n",
    "    },\n",
    "]\n",
    "\n",
    "station_metadata = pd.read_csv(SBB_STATION_PATH, sep=';')\n",
    "station_metadata['abbreviation_clean'] = (\n",
    "    station_metadata['abbreviation'].astype(str).str.strip().str.upper()\n",
    ")\n",
    "stop_point_mask = station_metadata['stopPoint'].astype(str).str.lower() == 'true'\n",
    "station_abbreviation_set = set(\n",
    "    station_metadata.loc[stop_point_mask, 'abbreviation_clean'].dropna().tolist()\n",
    ")\n",
    "station_abbreviation_set.discard('NAN')\n",
    "print('Loaded station reference table with', len(station_abbreviation_set), 'stop-point abbreviations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_geopos(value):\n",
    "    if isinstance(value, str) and ',' in value:\n",
    "        lat_str, lon_str = value.split(',', 1)\n",
    "        try:\n",
    "            lat = float(lat_str.strip())\n",
    "            lon = float(lon_str.strip())\n",
    "        except ValueError:\n",
    "            return None\n",
    "        if -90 <= lat <= 90 and -180 <= lon <= 180:\n",
    "            return lat, lon\n",
    "    return None\n",
    "\n",
    "def infer_station_flag(node_id, node_data):\n",
    "    flag = node_data.get('is_station')\n",
    "    if flag is not None:\n",
    "        return bool(flag)\n",
    "    abbr = node_data.get('abbreviation') or node_id\n",
    "    abbr_clean = (abbr or '').strip().upper()\n",
    "    if abbr_clean and abbr_clean in station_abbreviation_set:\n",
    "        return True\n",
    "    rows = node_data.get('rows') or []\n",
    "    for row in rows:\n",
    "        abbr_row = row.get('Station abbreviation')\n",
    "        if isinstance(abbr_row, str) and abbr_row.strip().upper() in station_abbreviation_set:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_contexts = []\n",
    "for cfg in DATASET_CONFIGS:\n",
    "    candidate_paths = [cfg['path']] + cfg.get('fallback_paths', [])\n",
    "    path = next((p for p in candidate_paths if p.exists()), None)\n",
    "    if path is None:\n",
    "        expected = ', '.join(str(p) for p in candidate_paths)\n",
    "        print(f\"Skipping {cfg['label']} (no existing graph files among: {expected})\")\n",
    "        continue\n",
    "    if path != cfg['path']:\n",
    "        print(f\"Using fallback graph {path} for {cfg['label']}\")\n",
    "    with path.open('rb') as f:\n",
    "        G = pickle.load(f)\n",
    "    node_records = []\n",
    "    positions = {}\n",
    "    missing = []\n",
    "    station_count = 0\n",
    "    for node_id, data in G.nodes(data=True):\n",
    "        lat = data.get('lat')\n",
    "        lon = data.get('lon')\n",
    "        if lat is None or lon is None:\n",
    "            coords = None\n",
    "            for row in data.get('rows', []):\n",
    "                coords = parse_geopos(row.get('Geopos')) or parse_geopos(row.get('Geopos_didok'))\n",
    "                if coords:\n",
    "                    lat, lon = coords\n",
    "                    break\n",
    "        if lat is None or lon is None:\n",
    "            missing.append(node_id)\n",
    "            continue\n",
    "        is_station = infer_station_flag(node_id, data)\n",
    "        station_count += int(is_station)\n",
    "        label = data.get('label') or data.get('name') or node_id\n",
    "        record = {\n",
    "            'dataset': cfg['key'],\n",
    "            'dataset_label': cfg['label'],\n",
    "            'node_id': node_id,\n",
    "            'label': label,\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'is_station': bool(is_station),\n",
    "        }\n",
    "        node_records.append(record)\n",
    "        positions[node_id] = (lat, lon)\n",
    "    infra_count = len(node_records) - station_count\n",
    "    dataset_contexts.append({\n",
    "        'config': cfg,\n",
    "        'graph': G,\n",
    "        'graph_path': path,\n",
    "        'node_records': node_records,\n",
    "        'positions': positions,\n",
    "        'missing_nodes': missing,\n",
    "    })\n",
    "    print(f\"{cfg['label']}: plotted {len(node_records)} nodes (stations {station_count}, infrastructure {infra_count}, missing coords {len(missing)})\")\n",
    "\n",
    "if not dataset_contexts:\n",
    "    raise RuntimeError('No graph files were found. Generate them in the exploration notebook first.')\n",
    "\n",
    "context_by_key = {ctx['config']['key']: ctx for ctx in dataset_contexts}\n",
    "print('Datasets loaded:', ', '.join(context_by_key.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import folium\n",
    "\n",
    "def build_dataset_map(ctx, zoom_start=8):\n",
    "    node_df = pd.DataFrame(ctx['node_records'])\n",
    "    if node_df.empty:\n",
    "        raise ValueError(f\"Dataset {ctx['config']['label']} has no plottable nodes.\")\n",
    "    center_lat = node_df['lat'].mean()\n",
    "    center_lon = node_df['lon'].mean()\n",
    "    cfg = ctx['config']\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=zoom_start, tiles='CartoDB Positron')\n",
    "    edges_fg = folium.FeatureGroup(name=f\"{cfg['label']} – edges\", show=True)\n",
    "    for u, v in ctx['graph'].edges():\n",
    "        if u not in ctx['positions'] or v not in ctx['positions']:\n",
    "            continue\n",
    "        lat1, lon1 = ctx['positions'][u]\n",
    "        lat2, lon2 = ctx['positions'][v]\n",
    "        if None in (lat1, lon1, lat2, lon2):\n",
    "            continue\n",
    "        folium.PolyLine([[lat1, lon1], [lat2, lon2]], color=cfg['edge_color'], weight=1, opacity=0.6).add_to(edges_fg)\n",
    "    edges_fg.add_to(m)\n",
    "    station_color, infra_color = cfg['node_colors']\n",
    "    stations_fg = folium.FeatureGroup(name=f\"{cfg['label']} – stations\", show=True)\n",
    "    infra_fg = folium.FeatureGroup(name=f\"{cfg['label']} – infrastructure\", show=True)\n",
    "    for rec in ctx['node_records']:\n",
    "        layer = stations_fg if rec['is_station'] else infra_fg\n",
    "        color = station_color if rec['is_station'] else infra_color\n",
    "        popup = folium.Popup(\n",
    "            f\"<b>{rec['label']}</b><br>ID: {rec['node_id']}<br>Dataset: {cfg['label']}\",\n",
    "            max_width=260,\n",
    "        )\n",
    "        folium.CircleMarker(\n",
    "            location=[rec['lat'], rec['lon']],\n",
    "            radius=4 if rec['is_station'] else 3,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.9,\n",
    "            weight=1,\n",
    "            tooltip=rec['label'],\n",
    "            popup=popup,\n",
    "        ).add_to(layer)\n",
    "    stations_fg.add_to(m)\n",
    "    infra_fg.add_to(m)\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7046d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sbb_ctx = context_by_key.get('sbb')\n",
    "if sbb_ctx is None:\n",
    "    print('SBB graph not available. Run the exploration notebook with DATA_SOURCE=\"sbb\" first.')\n",
    "else:\n",
    "    print('Rendering SBB map from', sbb_ctx['graph_path'])\n",
    "    sbb_map = build_dataset_map(sbb_ctx, zoom_start=8)\n",
    "    display(sbb_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93db7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "swiss_ctx = context_by_key.get('swisstopo')\n",
    "if swiss_ctx is None:\n",
    "    print('Nationwide graph not available. Run the exploration notebook with DATA_SOURCE=\"swisstopo\".')\n",
    "else:\n",
    "    print('Rendering nationwide map from', swiss_ctx['graph_path'])\n",
    "    swiss_map = build_dataset_map(swiss_ctx, zoom_start=7)\n",
    "    display(swiss_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fea148",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FOCUS_DATASET_KEY = 'sbb'  # switch to 'swisstopo' to inspect nationwide nodes\n",
    "FOCUS_NODE_IDS = ['ASZW', 'ASZO', 'ASKO', 'ASSW']  # replace with node ids of interest\n",
    "\n",
    "ctx = context_by_key.get(FOCUS_DATASET_KEY)\n",
    "if ctx is None:\n",
    "    print(f\"Dataset '{FOCUS_DATASET_KEY}' is not loaded. Available: {list(context_by_key.keys())}\")\n",
    "elif not FOCUS_NODE_IDS:\n",
    "    print('Provide at least one node id in FOCUS_NODE_IDS to center the map.')\n",
    "else:\n",
    "    subset = [rec for rec in ctx['node_records'] if rec['node_id'] in FOCUS_NODE_IDS]\n",
    "    if not subset:\n",
    "        print('No matching nodes found for the requested IDs.')\n",
    "    else:\n",
    "        display(pd.DataFrame(subset))\n",
    "        focus_lat = pd.DataFrame(subset)['lat'].mean()\n",
    "        focus_lon = pd.DataFrame(subset)['lon'].mean()\n",
    "        focus_map = folium.Map(location=[focus_lat, focus_lon], zoom_start=13, tiles='CartoDB Positron')\n",
    "        for rec in subset:\n",
    "            color = ctx['config']['node_colors'][0] if rec['is_station'] else ctx['config']['node_colors'][1]\n",
    "            folium.CircleMarker(\n",
    "                location=[rec['lat'], rec['lon']],\n",
    "                radius=6,\n",
    "                color=color,\n",
    "                fill=True,\n",
    "                fill_color=color,\n",
    "                fill_opacity=0.95,\n",
    "                tooltip=f\"{rec['label']} ({rec['node_id']})\",\n",
    "            ).add_to(focus_map)\n",
    "        for u, v in ctx['graph'].edges():\n",
    "            if {u, v}.issubset(set(FOCUS_NODE_IDS)) and u in ctx['positions'] and v in ctx['positions']:\n",
    "                lat1, lon1 = ctx['positions'][u]\n",
    "                lat2, lon2 = ctx['positions'][v]\n",
    "                folium.PolyLine([[lat1, lon1], [lat2, lon2]], color=ctx['config']['edge_color'], weight=2).add_to(focus_map)\n",
    "        focus_map\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Network Science Venv",
   "language": "python",
   "name": "network_science_venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
